Creating dataset for TF:

path to the workspace: 

/Users/azoryk/models/inception

all the labels in 'labels.txt' should be the same name as in folders

bazel-bin/inception/build_image_data \
  --train_directory="/Users/azoryk/Desktop/tf_dataset/train" \
  --validation_directory="/Users/azoryk/Desktop/tf_dataset/validation" \
  --output_directory="/Users/azoryk/Desktop/tf_dataset"/input_dataset \
  --labels_file="/Users/azoryk/Desktop/tf_dataset/labels.txt" \
  --train_shards=128 \
  --validation_shards=24 \
  --num_threads=8


Training

path to the workspace:
/Users/azoryk/models/slim


DATASET_DIR=/Users/azoryk/Desktop/tf_dataset
TRAIN_DIR=/Users/azoryk/Desktop/tf_dataset
python train_image_classifier.py \
    --train_dir=/Users/azoryk/Desktop/tf_dataset/input_dataset \
    --dataset_split_name=train \
    --dataset_dir=/Users/azoryk/Desktop/tf_dataset \
    --model_name=inception_v3
    --learning_rate 0.05

Error: InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'InceptionV3/Logits/Conv2d_1c_1x1/biases/RMSProp_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.
	 [[Node: InceptionV3/Logits/Conv2d_1c_1x1/biases/RMSProp_1 = VariableV2[_class=["loc:@InceptionV3/Logits/Conv2d_1c_1x1/biases"], container="", dtype=DT_FLOAT, shape=[1001], shared_name="", _device="/device:GPU:0"]()]]


Docker training: 

workspace
/Users/azoryk/tf_files


run TS with docker 

docker run -it \
  --publish 6006:6006 \
  --volume ${HOME}/tf_files:/tf_files \
  --workdir /tf_files \
  tensorflow/tensorflow:1.1.0 bash


the root folder should be: root@9e70dd480e6d:/tf_files#

python retrain.py \
  --bottleneck_dir=bottlenecks \
  --how_many_training_steps=500 \
  --model_dir=inception \
  --summaries_dir=training_summaries/basic \
  --output_graph=retrained_graph.pb \
  --output_labels=retrained_labels.txt \
  --image_dir=german_poi_photos


python label_image.py /Users/azoryk/tf_files/testing/458440718-10.jpg




VGG 16 inside Docker
https://hub.docker.com/r/dominicbreuker/vgg_docker/

Docker Pull Command
docker pull dominicbreuker/vgg_docker


docker run -it --rm -v $DATA_DIR:/data a -v $OUTPUT_DIR:/Users/azoryk/Desktop/output dominicbreuker/vgg_docker:latest python /vgg_16/extractor.py




Checkpoints creation

VGG-16:

CHECKPOINT_DIR=/tf_files/checkpoints
mkdir ${CHECKPOINT_DIR}
wget http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz
wget http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz
tar -xvf vgg_16_2016_08_28.tar.gz
tar -xvf inception_v3_2016_08_28.tar.gz
mv inception_v3.ckpt ${CHECKPOINT_DIR}
rm inception_v3_2016_08_28.tar.gz

ResNet 50:

$ DATASET_DIR=/tmp/flowers
$ TRAIN_DIR=/tmp/flowers-models/inception_v3
$ CHECKPOINT_PATH=/tmp/my_checkpoints/inception_v3.ckpt
$ python train_image_classifier.py \
    --train_dir=${TRAIN_DIR} \
    --dataset_dir=${DATASET_DIR} \
    --dataset_name=flowers \
    --dataset_split_name=train \
    --model_name=inception_v3 \
    --checkpoint_path=${CHECKPOINT_PATH} \
    --checkpoint_exclude_scopes=InceptionV3/Logits,InceptionV3/AuxLogits \
    --trainable_scopes=InceptionV3/Logits,InceptionV3/AuxLogits

Fine-tuning a model from an existing checkpoint


$ DATASET_DIR=/tf_files/german_poi_photos
$ TRAIN_DIR=/tmp/flowers-models/inception_v3
$ CHECKPOINT_PATH=/tf_files/my_checkpoints/inception_v3.ckpt
$ python train_image_classifier.py \
    --train_dir=${TRAIN_DIR} \
    --dataset_dir=${DATASET_DIR} \
    --dataset_name=flowers \
    --dataset_split_name=train \
    --model_name=inception_v3 \
    --checkpoint_path=${CHECKPOINT_PATH} \
    --checkpoint_exclude_scopes=InceptionV3/Logits,InceptionV3/AuxLogits \
    --trainable_scopes=InceptionV3/Logits,InceptionV3/AuxLogits
